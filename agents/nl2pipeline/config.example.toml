[manager]
url = "http://127.0.0.1:8080"
timeout_secs = 10

[llm]
# OpenAI-compatible base URL. For OpenAI public API, use:
#   https://api.openai.com/v1
# For DeepSeek, the docs use:
#   https://api.deepseek.com/beta
# The client does NOT auto-add /v1; include the correct prefix in base_url.
base_url = "https://api.deepseek.com/beta"
timeout_secs = 120

# Prefer reading secrets from environment variables.
api_key_env = "DEEPSEEK_API_KEY"

# Chat-completions model name.
model = "deepseek-chat"

# Whether to use SSE streaming for chat completions (helps responsiveness and avoids long blocking reads).
stream = true

# Whether to request JSON mode (response_format={"type":"json_object"}).
json_mode = true

[stream]
# Optional default stream for the session. If empty, the agent will pick a stream
# only when the user prompt explicitly mentions an existing stream name; otherwise
# it will ask the user to choose.
default = ""

[sink]
broker_url = "tcp://127.0.0.1:1883"
topic = "/nl2pipeline/out"
qos = 0

[repl]
check_max_attempts = 3
