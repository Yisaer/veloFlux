use crate::{DEFAULT_BROKER_URL, MQTT_QOS, SINK_TOPIC, storage_bridge};
use axum::{
    Json,
    extract::{Path, Query, State},
    http::{HeaderValue, StatusCode, header},
    response::IntoResponse,
};
use flow::EncoderRegistry;
use flow::FlowInstance;
use flow::pipeline::{
    KuksaSinkProps, MqttSinkProps, NopSinkProps, PipelineDefinition, PipelineError,
    PipelineOptions, PipelineStatus, PipelineStopMode, PlanCacheOptions, SinkDefinition, SinkProps,
    SinkType,
};
use flow::planner::sink::{CommonSinkProps, SinkEncoderConfig};
use serde::{Deserialize, Serialize};
use serde_json::{Map as JsonMap, Value as JsonValue};
use std::collections::HashMap;
use std::sync::Arc;
use std::time::Duration;
use storage::{StorageError, StorageManager, StoredPipelineDesiredState, StoredPipelineRunState};
use tokio::sync::{Mutex, OwnedSemaphorePermit, Semaphore, TryAcquireError};

#[derive(Clone)]
pub struct AppState {
    pub instance: Arc<FlowInstance>,
    pub storage: Arc<StorageManager>,
    pipeline_op_locks: Arc<Mutex<HashMap<String, Arc<Semaphore>>>>,
}

impl AppState {
    pub fn new(instance: FlowInstance, storage: StorageManager) -> Self {
        Self {
            instance: Arc::new(instance),
            storage: Arc::new(storage),
            pipeline_op_locks: Arc::new(Mutex::new(HashMap::new())),
        }
    }

    pub async fn try_acquire_pipeline_op(
        &self,
        pipeline_id: &str,
    ) -> Result<OwnedSemaphorePermit, TryAcquireError> {
        let semaphore = {
            let mut guard = self.pipeline_op_locks.lock().await;
            guard
                .entry(pipeline_id.to_string())
                .or_insert_with(|| Arc::new(Semaphore::new(1)))
                .clone()
        };
        semaphore.try_acquire_owned()
    }
}

#[derive(Deserialize, Serialize)]
pub struct CreatePipelineRequest {
    pub id: String,
    pub sql: String,
    #[serde(default)]
    pub sinks: Vec<CreatePipelineSinkRequest>,
    #[serde(default)]
    pub options: PipelineOptionsRequest,
}

#[derive(Deserialize, Serialize)]
pub struct UpsertPipelineRequest {
    pub sql: String,
    #[serde(default)]
    pub sinks: Vec<CreatePipelineSinkRequest>,
    #[serde(default)]
    pub options: PipelineOptionsRequest,
}

#[derive(Deserialize, Serialize, Default, Clone)]
#[serde(default)]
pub struct PipelineOptionsRequest {
    #[serde(rename = "plan_cache")]
    pub plan_cache: PlanCacheOptionsRequest,
    #[serde(default)]
    pub eventtime: EventtimeOptionsRequest,
}

#[derive(Deserialize, Serialize, Default, Clone)]
#[serde(default)]
pub struct EventtimeOptionsRequest {
    pub enabled: bool,
    #[serde(rename = "lateTolerance")]
    pub late_tolerance_ms: u64,
}

#[derive(Deserialize, Serialize, Default, Clone)]
#[serde(default)]
pub struct PlanCacheOptionsRequest {
    pub enabled: bool,
}

#[derive(Serialize)]
pub struct CreatePipelineResponse {
    pub id: String,
    pub status: String,
}

#[derive(Serialize)]
pub struct ListPipelineItem {
    pub id: String,
    pub status: String,
}

#[derive(Serialize)]
pub struct GetPipelineResponse {
    pub id: String,
    pub status: String,
    pub spec: CreatePipelineRequest,
}

#[derive(Deserialize)]
#[serde(default)]
pub(crate) struct CollectStatsQuery {
    timeout_ms: u64,
}

impl Default for CollectStatsQuery {
    fn default() -> Self {
        Self { timeout_ms: 5_000 }
    }
}

#[derive(Deserialize)]
#[serde(default)]
pub(crate) struct StopPipelineQuery {
    mode: String,
    timeout_ms: u64,
}

impl Default for StopPipelineQuery {
    fn default() -> Self {
        Self {
            mode: "quick".to_string(),
            timeout_ms: 5_000,
        }
    }
}

fn parse_stop_mode(mode: &str) -> Result<PipelineStopMode, String> {
    match mode.trim().to_ascii_lowercase().as_str() {
        "" | "quick" => Ok(PipelineStopMode::Quick),
        "graceful" => Ok(PipelineStopMode::Graceful),
        other => Err(format!("unsupported stop mode: {other}")),
    }
}

fn busy_response(id: &str) -> axum::response::Response {
    (
        StatusCode::CONFLICT,
        format!("pipeline {id} is busy processing another command"),
    )
        .into_response()
}

fn stored_state_label(state: Option<StoredPipelineRunState>) -> String {
    match state.map(|s| s.desired_state) {
        Some(StoredPipelineDesiredState::Running) => "running".to_string(),
        _ => "stopped".to_string(),
    }
}

#[derive(Deserialize, Serialize, Clone)]
pub struct CreatePipelineSinkRequest {
    pub id: Option<String>,
    #[serde(rename = "type")]
    pub sink_type: String,
    #[serde(default)]
    pub props: SinkPropsRequest,
    #[serde(rename = "commonSinkProps", default)]
    pub common: CommonSinkPropsRequest,
    #[serde(default)]
    pub encoder: EncoderConfigRequest,
}

#[derive(Deserialize, Serialize, Clone)]
#[serde(default)]
pub struct EncoderConfigRequest {
    #[serde(rename = "type")]
    pub encode_type: String,
    pub props: JsonMap<String, JsonValue>,
}

impl EncoderConfigRequest {
    fn new(encode_type: impl Into<String>, props: JsonMap<String, JsonValue>) -> Self {
        Self {
            encode_type: encode_type.into(),
            props,
        }
    }
}

impl Default for EncoderConfigRequest {
    fn default() -> Self {
        Self::new("json", JsonMap::new())
    }
}

#[derive(Deserialize, Serialize, Default, Clone)]
#[serde(default)]
pub struct SinkPropsRequest {
    #[serde(flatten)]
    fields: JsonMap<String, JsonValue>,
}

impl SinkPropsRequest {
    fn to_value(&self) -> JsonValue {
        JsonValue::Object(self.fields.clone())
    }
}

impl CommonSinkPropsRequest {
    fn to_common_props(&self) -> CommonSinkProps {
        let duration = self.batch_duration_ms.map(Duration::from_millis);
        CommonSinkProps {
            batch_count: self.batch_count,
            batch_duration: duration,
        }
    }
}

#[derive(Deserialize, Serialize, Default, Clone)]
#[serde(default)]
pub struct MqttSinkPropsRequest {
    pub broker_url: Option<String>,
    pub topic: Option<String>,
    pub qos: Option<u8>,
    pub retain: Option<bool>,
    pub client_id: Option<String>,
    pub connector_key: Option<String>,
}

#[derive(Deserialize, Serialize, Default, Clone)]
#[serde(default)]
pub struct NopSinkPropsRequest {
    pub log: Option<bool>,
}

#[derive(Deserialize, Serialize, Default, Clone)]
#[serde(default)]
pub struct CommonSinkPropsRequest {
    #[serde(rename = "batchCount")]
    pub batch_count: Option<usize>,
    #[serde(rename = "batchDuration")]
    pub batch_duration_ms: Option<u64>,
}

#[derive(Deserialize)]
struct KuksaSinkPropsRequest {
    pub addr: Option<String>,
    #[serde(rename = "vssPath")]
    pub vss_path: Option<String>,
}

pub async fn create_pipeline_handler(
    State(state): State<AppState>,
    Json(req): Json<CreatePipelineRequest>,
) -> impl IntoResponse {
    if let Err(err) = validate_create_request(&req) {
        return (StatusCode::BAD_REQUEST, err).into_response();
    }
    let _permit = match state.try_acquire_pipeline_op(&req.id).await {
        Ok(permit) => permit,
        Err(TryAcquireError::NoPermits) => return busy_response(&req.id),
        Err(TryAcquireError::Closed) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                "pipeline operation guard closed".to_string(),
            )
                .into_response();
        }
    };
    let encoder_registry = state.instance.encoder_registry();
    let definition = match build_pipeline_definition(&req, encoder_registry.as_ref()) {
        Ok(def) => def,
        Err(err) => return (StatusCode::BAD_REQUEST, err).into_response(),
    };
    let stored = match storage_bridge::stored_pipeline_from_request(&req) {
        Ok(stored) => stored,
        Err(err) => return (StatusCode::BAD_REQUEST, err).into_response(),
    };
    match state.storage.create_pipeline(stored.clone()) {
        Ok(()) => {}
        Err(StorageError::AlreadyExists(_)) => {
            return (
                StatusCode::CONFLICT,
                format!("pipeline {} already exists", req.id),
            )
                .into_response();
        }
        Err(err) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("failed to persist pipeline {}: {err}", req.id),
            )
                .into_response();
        }
    }

    let build_result = match state.instance.create_pipeline_with_plan_cache(
        definition,
        flow::planner::plan_cache::PlanCacheInputs {
            pipeline_raw_json: stored.raw_json.clone(),
            streams_raw_json: Vec::new(),
            snapshot: None,
        },
    ) {
        Ok(result) => result,
        Err(PipelineError::AlreadyExists(_)) => {
            let _ = state.storage.delete_pipeline(&stored.id);
            return (
                StatusCode::CONFLICT,
                format!("pipeline {} already exists", req.id),
            )
                .into_response();
        }
        Err(err) => {
            let _ = state.storage.delete_pipeline(&stored.id);
            return (
                StatusCode::BAD_REQUEST,
                format!("failed to create pipeline {}: {err}", req.id),
            )
                .into_response();
        }
    };

    if let Some(logical_ir) = build_result.logical_plan_ir {
        match storage_bridge::build_plan_snapshot(
            state.storage.as_ref(),
            &stored.id,
            &stored.raw_json,
            &build_result.snapshot.streams,
            logical_ir,
        )
        .and_then(|record| {
            state
                .storage
                .put_plan_snapshot(record)
                .map_err(|e| e.to_string())
        }) {
            Ok(()) => {}
            Err(err) => {
                let _ = state.instance.delete_pipeline(&stored.id).await;
                let _ = state.storage.delete_pipeline(&stored.id);
                return (
                    StatusCode::INTERNAL_SERVER_ERROR,
                    format!(
                        "pipeline {} created but failed to persist plan cache: {err}",
                        req.id
                    ),
                )
                    .into_response();
            }
        }
    }

    let snapshot = build_result.snapshot;
    {
        tracing::info!(pipeline_id = %snapshot.definition.id(), "pipeline created");
        (
            StatusCode::CREATED,
            Json(CreatePipelineResponse {
                id: snapshot.definition.id().to_string(),
                status: status_label(snapshot.status),
            }),
        )
            .into_response()
    }
}

pub async fn upsert_pipeline_handler(
    State(state): State<AppState>,
    Path(id): Path<String>,
    Json(req): Json<UpsertPipelineRequest>,
) -> impl IntoResponse {
    let id = id.trim().to_string();
    let create_req = CreatePipelineRequest {
        id: id.clone(),
        sql: req.sql,
        sinks: req.sinks,
        options: req.options,
    };
    if let Err(err) = validate_create_request(&create_req) {
        return (StatusCode::BAD_REQUEST, err).into_response();
    }

    let _permit = match state.try_acquire_pipeline_op(&id).await {
        Ok(permit) => permit,
        Err(TryAcquireError::NoPermits) => return busy_response(&id),
        Err(TryAcquireError::Closed) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                "pipeline operation guard closed".to_string(),
            )
                .into_response();
        }
    };

    let old_pipeline = match state.storage.get_pipeline(&id) {
        Ok(pipeline) => pipeline,
        Err(err) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("failed to read pipeline {id} from storage: {err}"),
            )
                .into_response();
        }
    };

    let old_desired_state = match state.storage.get_pipeline_run_state(&id) {
        Ok(Some(state)) => state.desired_state,
        Ok(None) => StoredPipelineDesiredState::Stopped,
        Err(err) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("failed to read pipeline {id} run state from storage: {err}"),
            )
                .into_response();
        }
    };

    let encoder_registry = state.instance.encoder_registry();
    let definition = match build_pipeline_definition(&create_req, encoder_registry.as_ref()) {
        Ok(definition) => definition,
        Err(err) => return (StatusCode::BAD_REQUEST, err).into_response(),
    };

    if let Err(err) = state.instance.explain_pipeline_definition(&definition) {
        return (
            StatusCode::BAD_REQUEST,
            format!("invalid pipeline spec: {err}"),
        )
            .into_response();
    }

    if old_pipeline.is_some() {
        match state.instance.delete_pipeline(&id).await {
            Ok(_) | Err(PipelineError::NotFound(_)) => {}
            Err(err) => {
                return (
                    StatusCode::BAD_REQUEST,
                    format!("failed to delete pipeline {id} in runtime: {err}"),
                )
                    .into_response();
            }
        }
        match state.storage.delete_pipeline(&id) {
            Ok(_) | Err(StorageError::NotFound(_)) => {}
            Err(err) => {
                return (
                    StatusCode::INTERNAL_SERVER_ERROR,
                    format!("failed to delete pipeline {id} from storage: {err}"),
                )
                    .into_response();
            }
        }
    }

    let stored = match storage_bridge::stored_pipeline_from_request(&create_req) {
        Ok(stored) => stored,
        Err(err) => return (StatusCode::BAD_REQUEST, err).into_response(),
    };
    match state.storage.create_pipeline(stored.clone()) {
        Ok(()) => {}
        Err(StorageError::AlreadyExists(_)) => {
            return (
                StatusCode::CONFLICT,
                format!("pipeline {id} already exists"),
            )
                .into_response();
        }
        Err(err) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("failed to persist pipeline {id}: {err}"),
            )
                .into_response();
        }
    }

    let build_result = match state.instance.create_pipeline_with_plan_cache(
        definition,
        flow::planner::plan_cache::PlanCacheInputs {
            pipeline_raw_json: stored.raw_json.clone(),
            streams_raw_json: Vec::new(),
            snapshot: None,
        },
    ) {
        Ok(result) => result,
        Err(err) => {
            let _ = state.storage.delete_pipeline(&id);
            return (
                StatusCode::BAD_REQUEST,
                format!("failed to create pipeline {id}: {err}"),
            )
                .into_response();
        }
    };

    if let Some(logical_ir) = build_result.logical_plan_ir {
        match storage_bridge::build_plan_snapshot(
            state.storage.as_ref(),
            &stored.id,
            &stored.raw_json,
            &build_result.snapshot.streams,
            logical_ir,
        )
        .and_then(|record| {
            state
                .storage
                .put_plan_snapshot(record)
                .map_err(|e| e.to_string())
        }) {
            Ok(()) => {}
            Err(err) => {
                let _ = state.instance.delete_pipeline(&id).await;
                let _ = state.storage.delete_pipeline(&id);
                return (
                    StatusCode::INTERNAL_SERVER_ERROR,
                    format!("pipeline {id} created but failed to persist plan cache: {err}"),
                )
                    .into_response();
            }
        }
    }

    if matches!(old_desired_state, StoredPipelineDesiredState::Running) {
        if let Err(err) = state
            .storage
            .put_pipeline_run_state(StoredPipelineRunState {
                pipeline_id: id.clone(),
                desired_state: StoredPipelineDesiredState::Running,
            })
        {
            let _ = state.instance.delete_pipeline(&id).await;
            let _ = state.storage.delete_pipeline(&id);
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("failed to persist pipeline {id} desired state: {err}"),
            )
                .into_response();
        }

        if let Err(err) = state.instance.start_pipeline(&id) {
            tracing::error!(
                pipeline_id = %id,
                error = %err,
                "failed to start pipeline after upsert, leaving stopped"
            );
            let _ = state
                .storage
                .put_pipeline_run_state(StoredPipelineRunState {
                    pipeline_id: id.clone(),
                    desired_state: StoredPipelineDesiredState::Stopped,
                });
        }
    }

    let status = stored_state_label(state.storage.get_pipeline_run_state(&id).unwrap_or(None));
    Json(CreatePipelineResponse { id, status }).into_response()
}

pub async fn get_pipeline_handler(
    State(state): State<AppState>,
    Path(id): Path<String>,
) -> impl IntoResponse {
    let stored = match state.storage.get_pipeline(&id) {
        Ok(Some(pipeline)) => pipeline,
        Ok(None) => {
            return (StatusCode::NOT_FOUND, format!("pipeline {id} not found")).into_response();
        }
        Err(err) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("failed to read pipeline {id} from storage: {err}"),
            )
                .into_response();
        }
    };

    let spec = match storage_bridge::pipeline_request_from_stored(&stored) {
        Ok(spec) => spec,
        Err(err) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("failed to decode stored pipeline {id}: {err}"),
            )
                .into_response();
        }
    };

    let run_state = match state.storage.get_pipeline_run_state(&id) {
        Ok(state) => state,
        Err(err) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("failed to read pipeline {id} run state from storage: {err}"),
            )
                .into_response();
        }
    };

    Json(GetPipelineResponse {
        id: id.clone(),
        status: stored_state_label(run_state),
        spec,
    })
    .into_response()
}

pub async fn explain_pipeline_handler(
    State(state): State<AppState>,
    Path(id): Path<String>,
) -> impl IntoResponse {
    match state.storage.get_pipeline(&id) {
        Ok(Some(_)) => {}
        Ok(None) => {
            return (StatusCode::NOT_FOUND, format!("pipeline {id} not found")).into_response();
        }
        Err(err) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("failed to read pipeline {id} from storage: {err}"),
            )
                .into_response();
        }
    }

    let explain = match state.instance.explain_pipeline(&id) {
        Ok(explain) => explain,
        Err(PipelineError::NotFound(_)) => {
            return (StatusCode::NOT_FOUND, format!("pipeline {id} not found")).into_response();
        }
        Err(err) => {
            return (
                StatusCode::BAD_REQUEST,
                format!("failed to explain pipeline {id}: {err}"),
            )
                .into_response();
        }
    };

    let mut response = explain.to_pretty_string().into_response();
    response.headers_mut().insert(
        header::CONTENT_TYPE,
        HeaderValue::from_static("text/plain; charset=utf-8"),
    );
    response
}

pub async fn collect_pipeline_stats_handler(
    State(state): State<AppState>,
    Path(id): Path<String>,
    Query(query): Query<CollectStatsQuery>,
) -> impl IntoResponse {
    let _permit = match state.try_acquire_pipeline_op(&id).await {
        Ok(permit) => permit,
        Err(TryAcquireError::NoPermits) => return busy_response(&id),
        Err(TryAcquireError::Closed) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                "pipeline operation guard closed".to_string(),
            )
                .into_response();
        }
    };

    match state.storage.get_pipeline(&id) {
        Ok(Some(_)) => {}
        Ok(None) => {
            return (StatusCode::NOT_FOUND, format!("pipeline {id} not found")).into_response();
        }
        Err(err) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("failed to read pipeline {id} from storage: {err}"),
            )
                .into_response();
        }
    }

    let timeout = Duration::from_millis(query.timeout_ms);
    match state.instance.collect_pipeline_stats(&id, timeout).await {
        Ok(stats) => (StatusCode::OK, Json(stats)).into_response(),
        Err(PipelineError::NotFound(_)) => {
            (StatusCode::NOT_FOUND, format!("pipeline {id} not found")).into_response()
        }
        Err(PipelineError::Runtime(err)) if err == flow::ProcessorError::Timeout.to_string() => (
            StatusCode::GATEWAY_TIMEOUT,
            format!("collect stats timeout for pipeline {id}"),
        )
            .into_response(),
        Err(err) => (
            StatusCode::BAD_REQUEST,
            format!("failed to collect pipeline {id} stats: {err}"),
        )
            .into_response(),
    }
}

pub async fn start_pipeline_handler(
    State(state): State<AppState>,
    Path(id): Path<String>,
) -> impl IntoResponse {
    let _permit = match state.try_acquire_pipeline_op(&id).await {
        Ok(permit) => permit,
        Err(TryAcquireError::NoPermits) => return busy_response(&id),
        Err(TryAcquireError::Closed) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                "pipeline operation guard closed".to_string(),
            )
                .into_response();
        }
    };
    match state.storage.get_pipeline(&id) {
        Ok(Some(_)) => {}
        Ok(None) => {
            return (StatusCode::NOT_FOUND, format!("pipeline {id} not found")).into_response();
        }
        Err(err) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("failed to read pipeline {id} from storage: {err}"),
            )
                .into_response();
        }
    }

    if let Err(err) = state
        .storage
        .put_pipeline_run_state(StoredPipelineRunState {
            pipeline_id: id.clone(),
            desired_state: StoredPipelineDesiredState::Running,
        })
    {
        return (
            StatusCode::INTERNAL_SERVER_ERROR,
            format!("failed to persist pipeline {id} desired state: {err}"),
        )
            .into_response();
    }

    match state.instance.start_pipeline(&id) {
        Ok(_) => {
            tracing::info!(pipeline_id = %id, "pipeline started");
            (StatusCode::OK, format!("pipeline {id} started")).into_response()
        }
        Err(PipelineError::NotFound(_)) => {
            let _ = state
                .storage
                .put_pipeline_run_state(StoredPipelineRunState {
                    pipeline_id: id.clone(),
                    desired_state: StoredPipelineDesiredState::Stopped,
                });
            (StatusCode::NOT_FOUND, format!("pipeline {id} not found")).into_response()
        }
        Err(err) => {
            let _ = state
                .storage
                .put_pipeline_run_state(StoredPipelineRunState {
                    pipeline_id: id.clone(),
                    desired_state: StoredPipelineDesiredState::Stopped,
                });
            (
                StatusCode::BAD_REQUEST,
                format!("failed to start pipeline {id}: {err}"),
            )
                .into_response()
        }
    }
}

pub async fn stop_pipeline_handler(
    State(state): State<AppState>,
    Path(id): Path<String>,
    Query(query): Query<StopPipelineQuery>,
) -> impl IntoResponse {
    let _permit = match state.try_acquire_pipeline_op(&id).await {
        Ok(permit) => permit,
        Err(TryAcquireError::NoPermits) => return busy_response(&id),
        Err(TryAcquireError::Closed) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                "pipeline operation guard closed".to_string(),
            )
                .into_response();
        }
    };
    match state.storage.get_pipeline(&id) {
        Ok(Some(_)) => {}
        Ok(None) => {
            return (StatusCode::NOT_FOUND, format!("pipeline {id} not found")).into_response();
        }
        Err(err) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                format!("failed to read pipeline {id} from storage: {err}"),
            )
                .into_response();
        }
    }

    let mode = match parse_stop_mode(&query.mode) {
        Ok(mode) => mode,
        Err(err) => return (StatusCode::BAD_REQUEST, err).into_response(),
    };
    let timeout = Duration::from_millis(query.timeout_ms);

    if let Err(err) = state
        .storage
        .put_pipeline_run_state(StoredPipelineRunState {
            pipeline_id: id.clone(),
            desired_state: StoredPipelineDesiredState::Stopped,
        })
    {
        return (
            StatusCode::INTERNAL_SERVER_ERROR,
            format!("failed to persist pipeline {id} desired state: {err}"),
        )
            .into_response();
    }

    match state.instance.stop_pipeline(&id, mode, timeout).await {
        Ok(_) => {
            tracing::info!(
                pipeline_id = %id,
                mode = %query.mode,
                timeout_ms = query.timeout_ms,
                "pipeline stopped"
            );
            (StatusCode::OK, format!("pipeline {id} stopped")).into_response()
        }
        Err(PipelineError::NotFound(_)) => {
            (StatusCode::NOT_FOUND, format!("pipeline {id} not found")).into_response()
        }
        Err(err) => (
            StatusCode::BAD_REQUEST,
            format!("failed to stop pipeline {id}: {err}"),
        )
            .into_response(),
    }
}

pub async fn delete_pipeline_handler(
    State(state): State<AppState>,
    Path(id): Path<String>,
) -> impl IntoResponse {
    let _permit = match state.try_acquire_pipeline_op(&id).await {
        Ok(permit) => permit,
        Err(TryAcquireError::NoPermits) => return busy_response(&id),
        Err(TryAcquireError::Closed) => {
            return (
                StatusCode::INTERNAL_SERVER_ERROR,
                "pipeline operation guard closed".to_string(),
            )
                .into_response();
        }
    };
    match state.instance.delete_pipeline(&id).await {
        Ok(_) => {
            if let Err(err) = state.storage.delete_pipeline(&id) {
                return (
                    StatusCode::INTERNAL_SERVER_ERROR,
                    format!(
                        "pipeline {id} deleted in runtime but failed to remove from storage: {err}"
                    ),
                )
                    .into_response();
            }
            (StatusCode::OK, format!("pipeline {id} deleted")).into_response()
        }
        Err(PipelineError::NotFound(_)) => {
            (StatusCode::NOT_FOUND, format!("pipeline {id} not found")).into_response()
        }
        Err(err) => (
            StatusCode::BAD_REQUEST,
            format!("failed to delete pipeline {id}: {err}"),
        )
            .into_response(),
    }
}

pub async fn list_pipelines(State(state): State<AppState>) -> impl IntoResponse {
    let runtime_status: HashMap<String, String> = state
        .instance
        .list_pipelines()
        .into_iter()
        .map(|snapshot| {
            (
                snapshot.definition.id().to_string(),
                status_label(snapshot.status),
            )
        })
        .collect();

    match state.storage.list_pipelines() {
        Ok(entries) => {
            let list = entries
                .into_iter()
                .map(|entry| {
                    let status = runtime_status
                        .get(&entry.id)
                        .cloned()
                        .unwrap_or_else(|| "stopped".to_string());
                    ListPipelineItem {
                        id: entry.id,
                        status,
                    }
                })
                .collect::<Vec<_>>();
            Json(list).into_response()
        }
        Err(err) => (
            StatusCode::INTERNAL_SERVER_ERROR,
            format!("failed to list pipelines: {err}"),
        )
            .into_response(),
    }
}

fn validate_create_request(req: &CreatePipelineRequest) -> Result<(), String> {
    if req.id.trim().is_empty() {
        return Err("pipeline id must not be empty".to_string());
    }
    if req.sql.trim().is_empty() {
        return Err("pipeline sql must not be empty".to_string());
    }
    if req.sinks.is_empty() {
        return Err("pipeline must define at least one sink".to_string());
    }
    Ok(())
}

pub(crate) fn build_pipeline_definition(
    req: &CreatePipelineRequest,
    encoder_registry: &EncoderRegistry,
) -> Result<PipelineDefinition, String> {
    let mut sinks = Vec::with_capacity(req.sinks.len());
    for (index, sink_req) in req.sinks.iter().enumerate() {
        let sink_id = sink_req
            .id
            .clone()
            .unwrap_or_else(|| format!("{}_sink_{index}", req.id));
        let sink_type = sink_req.sink_type.to_ascii_lowercase();
        let sink_definition = match sink_type.as_str() {
            "mqtt" => {
                let mqtt_props: MqttSinkPropsRequest =
                    serde_json::from_value(sink_req.props.to_value())
                        .map_err(|err| format!("invalid mqtt sink props: {err}"))?;
                let broker = mqtt_props
                    .broker_url
                    .unwrap_or_else(|| DEFAULT_BROKER_URL.to_string());
                let topic = mqtt_props.topic.unwrap_or_else(|| SINK_TOPIC.to_string());
                let qos = mqtt_props.qos.unwrap_or(MQTT_QOS);
                let retain = mqtt_props.retain.unwrap_or(false);

                let mut props = MqttSinkProps::new(broker, topic, qos).with_retain(retain);
                if let Some(client_id) = mqtt_props.client_id {
                    props = props.with_client_id(client_id);
                }
                if let Some(connector_key) = mqtt_props.connector_key {
                    props = props.with_connector_key(connector_key);
                }
                SinkDefinition::new(sink_id.clone(), SinkType::Mqtt, SinkProps::Mqtt(props))
            }
            "nop" => {
                let nop_props: NopSinkPropsRequest =
                    serde_json::from_value(sink_req.props.to_value())
                        .map_err(|err| format!("invalid nop sink props: {err}"))?;
                SinkDefinition::new(
                    sink_id.clone(),
                    SinkType::Nop,
                    SinkProps::Nop(NopSinkProps {
                        log: nop_props.log.unwrap_or(false),
                    }),
                )
            }
            "kuksa" => {
                let kuksa_props: KuksaSinkPropsRequest =
                    serde_json::from_value(sink_req.props.to_value())
                        .map_err(|err| format!("invalid kuksa sink props: {err}"))?;
                let addr = kuksa_props
                    .addr
                    .ok_or_else(|| "kuksa sink props missing addr".to_string())?;
                let vss_path = kuksa_props
                    .vss_path
                    .ok_or_else(|| "kuksa sink props missing vssPath".to_string())?;
                SinkDefinition::new(
                    sink_id.clone(),
                    SinkType::Kuksa,
                    SinkProps::Kuksa(KuksaSinkProps { addr, vss_path }),
                )
            }
            other => return Err(format!("unsupported sink type: {other}")),
        };

        let sink_definition = match sink_definition.sink_type {
            SinkType::Kuksa => {
                let encoder_config = SinkEncoderConfig::new("none", JsonMap::new());
                sink_definition.with_encoder(encoder_config)
            }
            _ => {
                let encoder_kind = sink_req.encoder.encode_type.clone();
                if !encoder_registry.is_registered(&encoder_kind) {
                    return Err(format!("encoder kind `{encoder_kind}` not registered"));
                }
                let encoder_config =
                    SinkEncoderConfig::new(encoder_kind, sink_req.encoder.props.clone());
                sink_definition.with_encoder(encoder_config)
            }
        }
        .with_common_props(sink_req.common.to_common_props());
        sinks.push(sink_definition);
    }
    let options = PipelineOptions {
        plan_cache: PlanCacheOptions {
            enabled: req.options.plan_cache.enabled,
        },
        eventtime: flow::pipeline::EventtimeOptions {
            enabled: req.options.eventtime.enabled,
            late_tolerance: Duration::from_millis(req.options.eventtime.late_tolerance_ms),
        },
    };
    Ok(PipelineDefinition::new(req.id.clone(), req.sql.clone(), sinks).with_options(options))
}

fn status_label(status: PipelineStatus) -> String {
    match status {
        PipelineStatus::Stopped => "stopped".to_string(),
        PipelineStatus::Running => "running".to_string(),
    }
}
